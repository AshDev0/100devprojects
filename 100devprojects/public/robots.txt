# robots.txt for 100devprojects.in

# Allow all search engines to crawl everything
User-agent: *
Allow: /

# Prioritize important sections for crawling
Allow: /blog/
Allow: /project/
Allow: /demos/

# Sitemap location (IMPORTANT!)
Sitemap: https://100devprojects.in/sitemap.xml

# Special instructions for Googlebot
User-agent: Googlebot
Allow: /
Crawl-delay: 0

# Bing bot
User-agent: Bingbot
Allow: /
Crawl-delay: 0