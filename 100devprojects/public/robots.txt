# robots.txt for 100devprojects.in

# Allow all search engines to crawl everything
User-agent: *
Allow: /

# Disallow crawling of specific directories (if needed)
# Disallow: /admin/
# Disallow: /api/
# Disallow: /private/

# Crawl-delay (optional, for slower crawling)
# Crawl-delay: 1

# Sitemap location (IMPORTANT!)
Sitemap: https://100devprojects.in/sitemap.xml

# Additional sitemaps (if you have multiple)